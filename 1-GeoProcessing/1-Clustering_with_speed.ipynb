{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBScan Clustering\n",
    "\n",
    "1. Using DBScan, find spatial clusters relevant to each user, typically home, work, or school.\n",
    "1. Also identify the speeds between each geo-tagged tweet.\n",
    "\n",
    "**Input**: Directory of Twitterers (in `geojsonl` format)<br>\n",
    "**Output**: Directory of Twitterers in a GeoPandas GeoDataFrame (written to JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_directory  = \"/data/chime/geo/matthew/brevard_zone_a_users/\"\n",
    "# output_directory = \"/data/chime/geo/matthew/brevard_zone_a_clustered_with_speed_gdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_directory  = \"/data/chime/geo/zone_a_users_full_contextual\"\n",
    "output_directory = \"/data/chime/geo/zone_a_full_contexual/stage1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be safe to \"run all\" if the above directories are set :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, json, matplotlib, iso8601, sys, time, datetime, pytz\n",
    "import numpy as np; import pandas as pd; import geopandas as gpd\n",
    "from shapely.geometry import shape, mapping, MultiPoint\n",
    "from multiprocessing import Pool, Manager;\n",
    "from dbscan_python import dbscan\n",
    "from geodistance import geodistance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1195 users in /data/chime/geo/zone_a_users_full_contextual\n"
     ]
    }
   ],
   "source": [
    "users_in = sorted(os.listdir(input_directory))\n",
    "print(\"Found {0} users in {1}\".format(len(users_in), input_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # #sample?\n",
    "# users_in = np.random.choice(users_in, 100, replace=False)\n",
    "# len(users_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read Users In... and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def worker_function(args):\n",
    "    \"\"\"\n",
    "    Input: User .geojsonl file\n",
    "    Returns: DataFrame with speed & clusters\n",
    "\n",
    "    #Process\n",
    "    1. Loads all of a user's tweets (parseable json per line, parse, strip down to details, sort by time)\n",
    "    2. Computes Clusters based on below EPS & MIN_PTS\n",
    "    3. Computes time, distance, and speed between each tweet\n",
    "    4. Puts it all into a DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    #Unpack the arguments\n",
    "    user_geojsonl_file, input_directory, q = args\n",
    "\n",
    "    EPS     = 100     #Max. Distance for points in the cluster... (In meters)                                                                                                                  \n",
    "    MIN_PTS = 3       #Minimum Points in a cluster...\n",
    "    \n",
    "    geo_tweets     = []\n",
    "    non_geo_tweets = []\n",
    "    for line in open(input_directory+\"/\"+user_geojsonl_file,'r'):\n",
    "        t = json.loads(line.strip())\n",
    "        if t['geometry']:\n",
    "            stripped = {\n",
    "                    'geometry': shape(t['geometry']),\n",
    "                    'coords'  : t['geometry']['coordinates'],\n",
    "                    'date'    : pd.Timestamp(t['properties']['postedTime']),\n",
    "                    'text'    : t['properties']['body'],\n",
    "                    'user'    : t['properties']['actor']['preferredUsername'],\n",
    "                    'uid'     : t['properties']['actor']['id'].split(\":\")[2],\n",
    "                    'tweet_id': t['properties']['id'].split(\":\")[2]\n",
    "                }\n",
    "            geo_tweets.append(stripped)\n",
    "        else:\n",
    "            t = {\n",
    "                    'date'    : pd.Timestamp(t['properties']['postedTime']),\n",
    "                    'text'    : t['properties']['body'],\n",
    "                    'user'    : t['properties']['actor']['preferredUsername'],\n",
    "                    'uid'     : t['properties']['actor']['id'].split(\":\")[2],\n",
    "                    'tweet_id': t['properties']['id'].split(\":\")[2]\n",
    "                }\n",
    "            non_geo_tweets.append(t)\n",
    "\n",
    "    #Exit case 1: There aren't enough points\n",
    "    if len(geo_tweets)<MIN_PTS:\n",
    "        q.put(1)\n",
    "        return None\n",
    "\n",
    "    #Ensure we're sorted by time (Safety measure, probably taking performance hit)\n",
    "    geo_tweets.sort(key=lambda t: t['date'])\n",
    "\n",
    "    #Clustering:\n",
    "    points = [t['coords'] for t in geo_tweets]\n",
    "    clusters = dbscan.dbscan(np.matrix([ [p[0] for p in points], [p[1] for p in points] ]), EPS, MIN_PTS)\n",
    "    \n",
    "    #Iterate through tweets & clusters to assign cluster & calcualte distances\n",
    "    for idx, t in enumerate(geo_tweets):\n",
    "        t['cluster'] = clusters[idx]\n",
    "        if idx>0:\n",
    "            p1 = t['geometry']\n",
    "            p2 = geo_tweets[idx-1]['geometry']\n",
    "            t['geo_delta'] = geodistance.distanceHaversine(p1.y,p1.x,p2.y,p2.x)[0]*1000\n",
    "    \n",
    "    #Now we can put all the tweets into a DataFrame!\n",
    "    \n",
    "    df = gpd.GeoDataFrame(geo_tweets+non_geo_tweets)\n",
    "\n",
    "    # If clusters were all -1, then return nothing, it couldn't cluster!\n",
    "    if not len(df.query('cluster>=0'))>=1:\n",
    "        q.put(2)\n",
    "        return None\n",
    "    df['time_delta'] = df['date'].diff()\n",
    "    df['speed'] = df.apply(lambda row: row['geo_delta']/ (row['time_delta'] / np.timedelta64(1, 's')), axis=1)\n",
    "    q.put(0)\n",
    "    return df.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1195 users...\n",
      "Processed: 1193, 99.8%Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-26:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-30:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-24:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-11:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-12:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-23:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-20:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-16:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-27:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"<ipython-input-6-72d62a30f3df>\", line 54, in worker_function\n",
      "    clusters = dbscan.dbscan(np.matrix([ [p[0] for p in points], [p[1] for p in points] ]), EPS, MIN_PTS)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 355, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/dbscan_python/dbscan.py\", line 79, in dbscan\n",
      "    if _expand_cluster(m, classifications, point_id, cluster_id, eps, min_points):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/dbscan_python/dbscan.py\", line 44, in _expand_cluster\n",
      "    results = _region_query(m, current_point, eps)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/dbscan_python/dbscan.py\", line 28, in _region_query\n",
      "    if _eps_neighborhood(m[:,point_id], m[:,i], eps):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/connection.py\", line 416, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/connection.py\", line 383, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/dbscan_python/dbscan.py\", line 22, in _eps_neighborhood\n",
      "    return _dist(p,q) < eps\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/dbscan_python/dbscan.py\", line 18, in _dist\n",
      "    return geodistance.distanceHaversine(p[1],p[0],q[1],q[0])[0]*1000\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/anderstj/Twitter-Movement-Derivation/1-GeoProcessing/geodistance/geodistance.py\", line 21, in distanceHaversine\n",
      "    dLat = math.radians(lat2 - lat1)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/numpy/matrixlib/defmatrix.py\", line 293, in __array_finalize__\n",
      "    self._getitem = False\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ca512e038dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProcessed: {0}, {1:.3g}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProcessed: {0}, {1:.3g}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 254, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.4/multiprocessing/queues.py\", line 354, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.4/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i,input_directory,q) for i in users_in]\n",
    "result = p.map_async(worker_function, args)\n",
    "\n",
    "sys.stderr.write(\"Processing {0} users...\\n\".format(len(users_in)))\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(1)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "\n",
    "values = result.get()\n",
    "users = [i for i in values if i is not None]\n",
    "nones = [i for i in values if i is None]\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Successfully processed {0} users\\n{1} Users failed\".format(len(users),len(nones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cluster_centroids(args):\n",
    "    df, q = args\n",
    "    centroids = df.groupby('cluster', as_index=False).aggregate({'geometry':lambda x: MultiPoint(list(x)).centroid})\n",
    "    centroids.rename(columns={'geometry' : 'cluster_center'}, inplace=True)\n",
    "    centroids.set_index(centroids.cluster, inplace=True)\n",
    "    centroids.set_value(-1,'cluster_center',None)\n",
    "    if q is not None:\n",
    "        q.put(1)\n",
    "    return df.merge(centroids, on='cluster', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i,q) for i in users]\n",
    "result = p.map_async(calculate_cluster_centroids, args)\n",
    "\n",
    "sys.stderr.write(\"Processing {0} users...\\n\".format(len(users)))\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        with open(\"load.log\",'w') as log:\n",
    "            log.write(\"\\rProcessed: {0}, {1:.3g}%\\n\".format(size, size/len(args)*100))\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(1)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "\n",
    "_users = result.get()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Write these users to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def safe_mapping(p):\n",
    "    if p==None or np.isnan(p).any():\n",
    "        return None\n",
    "    else:\n",
    "        return mapping(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def safe_json_export(args):\n",
    "    df, path, q = args\n",
    "    df = df.copy() #Safety measure for atomic conversions...\n",
    "    df['date'] = df['date'].apply(lambda t: datetime.datetime.strftime(t,'%Y-%m-%dT%H:%M:%SZ'))\n",
    "    df['time_delta'] = df['time_delta'] / np.timedelta64(1, 's')\n",
    "    df['cluster_center'] = df['cluster_center'].apply(lambda c: json.dumps(safe_mapping(c)))\n",
    "    uName = df.head(1).user.values[0].lower() # Grab username, always make it lowercase for sorting safety :) \n",
    "    \n",
    "    clean = df.where((pd.notnull(df)), None)\n",
    "    geojson = {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "    for _, row in clean.iterrows():\n",
    "        geom = safe_mapping(row.geometry)\n",
    "        feature = {'type':'Feature',\n",
    "                   'geometry':geom,\n",
    "                   'properties':row.to_dict()\n",
    "                    }\n",
    "        del feature['properties']['geometry']\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    with open(path+\"/\"+uName+'.geojson','w') as oFile:\n",
    "        json.dump(geojson, oFile) \n",
    "\n",
    "    if q is not None:\n",
    "        q.put(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, output_directory, q) for i in _users]\n",
    "result = p.map_async(safe_json_export, args)\n",
    "\n",
    "sys.stderr.write(\"Exporting {0} users to {1}\\n\".format(len(_users),output_directory))\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "p.close()\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
