{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, iso8601, fiona, pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Clean, Sort, Export from GNIP\n",
    "\n",
    "This notebook: \n",
    "\n",
    "1. Loads raw gnip data\n",
    "1. Filters for a geotag\n",
    "1. Identifies all tweets within an area of interest\n",
    "1. Finds Unique Users\n",
    "1. Writes full GNIP GEOJSONL files per user for users with at least 1 tweet in the area of interest\n",
    "\n",
    "## [Spark Status](http://epic-analytics.cs.colorado.edu:4040/jobs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the files\n",
    "raw_strings = sc.textFile('/data/chime/matthew/gnip-geo/*/*')\n",
    "\n",
    "#Filter out the duds\n",
    "strings = raw_strings.filter(lambda x: x!=\"\")\n",
    "\n",
    "#JSONs\n",
    "jsons  = strings.map(json.loads)\n",
    "\n",
    "tweet_jsons = jsons.filter(lambda x: 'info' not in x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load all the Tweets!\n",
    "### 2 Crucial Steps\n",
    "1. A lot of tweets do not actually have lat/lon that will work for our purposes\n",
    "1. The GNIP `geo` field is backwards from convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_geo(t):\n",
    "    t['geo']['coordinates'].reverse()\n",
    "    return t\n",
    "\n",
    "tweets_with_geo = tweet_jsons.filter(lambda t: 'geo' in t.keys())\n",
    "\n",
    "geo_tweets = tweets_with_geo.map(fix_geo)\n",
    "# geo_tweets.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that this is working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'actor': {u'displayName': u'Francisco Aguirre',\n",
      "            u'favoritesCount': 16,\n",
      "            u'followersCount': 161,\n",
      "            u'friendsCount': 391,\n",
      "            u'id': u'id:twitter.com:304010396',\n",
      "            u'image': u'https://pbs.twimg.com/profile_images/378800000377728270/38ef32f591f5da633484526d17bf9bfa_normal.jpeg',\n",
      "            u'languages': [u'es'],\n",
      "            u'link': u'http://www.twitter.com/fraconicr',\n",
      "            u'links': [{u'href': None, u'rel': u'me'}],\n",
      "            u'listedCount': 2,\n",
      "            u'location': {u'displayName': u'Tifton, GA',\n",
      "                          u'objectType': u'place'},\n",
      "            u'objectType': u'person',\n",
      "            u'postedTime': u'2011-05-23T19:45:25.000Z',\n",
      "            u'preferredUsername': u'fraconicr',\n",
      "            u'statusesCount': 549,\n",
      "            u'summary': None,\n",
      "            u'twitterTimeZone': u'Mountain Time (US & Canada)',\n",
      "            u'utcOffset': u'-21600',\n",
      "            u'verified': False},\n",
      " u'body': u'Bendiciones!!! @ Iglesia VIDA Abundante, Tifton GA https://t.co/Nry0UtDFrP',\n",
      " u'favoritesCount': 0,\n",
      " u'generator': {u'displayName': u'Instagram',\n",
      "                u'link': u'http://instagram.com'},\n",
      " u'geo': {u'coordinates': [-83.50866, 31.45691], u'type': u'Point'},\n",
      " u'gnip': {u'matching_rules': [{u'id': 8875133707607889286,\n",
      "                                u'tag': u'id:510,radii:undefined,center:[-83.41070337110324,31.36938776395649]'}],\n",
      "           u'urls': [{u'expanded_status': None,\n",
      "                      u'expanded_url': None,\n",
      "                      u'expanded_url_description': None,\n",
      "                      u'expanded_url_title': None,\n",
      "                      u'url': u'https://t.co/Nry0UtDFrP'}]},\n",
      " u'id': u'tag:search.twitter.com,2005:783610338239447041',\n",
      " u'link': u'http://twitter.com/fraconicr/statuses/783610338239447041',\n",
      " u'location': {u'country_code': u'Estados Unidos',\n",
      "               u'displayName': u'Tifton, GA',\n",
      "               u'geo': {u'coordinates': [[[-83.574733, 31.417053],\n",
      "                                          [-83.574733, 31.493153],\n",
      "                                          [-83.443045, 31.493153],\n",
      "                                          [-83.443045, 31.417053]]],\n",
      "                        u'type': u'Polygon'},\n",
      "               u'link': u'https://api.twitter.com/1.1/geo/id/cb6928008b209c4a.json',\n",
      "               u'name': u'Tifton',\n",
      "               u'objectType': u'place',\n",
      "               u'twitter_country_code': u'US',\n",
      "               u'twitter_place_type': u'city'},\n",
      " u'object': {u'id': u'object:search.twitter.com,2005:783610338239447041',\n",
      "             u'link': u'http://twitter.com/fraconicr/statuses/783610338239447041',\n",
      "             u'objectType': u'note',\n",
      "             u'postedTime': u'2016-10-05T10:10:38.000Z',\n",
      "             u'summary': u'Bendiciones!!! @ Iglesia VIDA Abundante, Tifton GA https://t.co/Nry0UtDFrP'},\n",
      " u'objectType': u'activity',\n",
      " u'postedTime': u'2016-10-05T10:10:38.000Z',\n",
      " u'provider': {u'displayName': u'Twitter',\n",
      "               u'link': u'http://www.twitter.com',\n",
      "               u'objectType': u'service'},\n",
      " u'retweetCount': 0,\n",
      " u'twitter_entities': {u'hashtags': [],\n",
      "                       u'symbols': [],\n",
      "                       u'urls': [{u'display_url': u'instagram.com/p/BLLWlskD133s\\u2026',\n",
      "                                  u'expanded_url': u'https://www.instagram.com/p/BLLWlskD133srPM7ASAirHlHblDm8UfojKJyeU0/',\n",
      "                                  u'indices': [51, 74],\n",
      "                                  u'url': u'https://t.co/Nry0UtDFrP'}],\n",
      "                       u'user_mentions': []},\n",
      " u'twitter_filter_level': u'low',\n",
      " u'twitter_lang': u'es',\n",
      " u'verb': u'post'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(geo_tweets.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Export subsets of the data as `.geojsonl` files\n",
    "This is not by user, this is all tweets in one file (i.e., BIG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "all_geo_tweets = tweets_with_geo.collect()\n",
    "write_full_tweets_to_geojsonl('all_geotagged_tweets_full', all_geo_tweets)\n",
    "write_bare_tweets_to_geojsonl('all_geotagged_tweets_bare', all_geo_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Group tweets by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[7] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_gb_user = geo_tweets.groupBy(lambda t: t['actor']['id'])\n",
    "tweets_gb_user.cache() #We should probably cache these? If we want to use them again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check on the status of this operation, should see a tuple of: `(user_id, iterable)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'id:twitter.com:1637120388',\n",
      " <pyspark.resultiterable.ResultIterable object at 0x7f655c1bc250>)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(tweets_gb_user.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    u_tweets = list(tuple_of_uid_tweets[1])\n",
    "    u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "    fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_simplified_tweets_to_geojsonl('../working_data/simplified_geo_contextual_all_users/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Write the `geo-tweet-streams` for EVERY user "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tweets_gb_user.foreach( write_out_simplified_geo_contextual )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Geographic Filtering\n",
    "\n",
    "Load the shapefile for Evacuation Zone (or whatever your bounds should be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import mapping, shape\n",
    "import fiona\n",
    "c = fiona.open('../EvacuationZones/FL_EvacZones/martin_palm_beach_inland_hull.geojson','r')\n",
    "pol = c.next()\n",
    "geom = shape(pol['geometry'])\n",
    "geom.is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT (-81.65430000000001 30.3181)\n",
      "TRUE? False\n",
      "TRUE? False\n",
      "POINT (-73.99753114562988 40.73093368341445)\n",
      "FALSE? False\n"
     ]
    }
   ],
   "source": [
    "#Set as a broadcst variable for spark\n",
    "zoneBroadcast = sc.broadcast(geom)\n",
    "#Testing (For ZoneA):\n",
    "in_bounds = shape({'type': \"Point\", 'coordinates': [-81.6543,30.3181]})\n",
    "print in_bounds\n",
    "print \"TRUE?\", zoneBroadcast.value.contains(in_bounds)\n",
    "print \"TRUE?\", in_bounds.within(zoneBroadcast.value)\n",
    "\n",
    "out_of_bounds = shape({\"type\": \"Point\",\"coordinates\": [-73.99753114562988,40.73093368341445]})\n",
    "print out_of_bounds\n",
    "print \"FALSE?\", zoneBroadcast.value.contains(out_of_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a function that takes an iterable and filters for users with a tweet in zoneA\n",
    "def has_tweet_in_bounds(iterable):\n",
    "    for t in iterable:\n",
    "        if zoneBroadcast.value.contains( shape(t['geo']) ):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the filter for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_tweets_with_a_tweet_in_zone_A = tweets_gb_user.filter(lambda _: has_tweet_in_bounds(_[1]))\n",
    "# user_tweets_with_a_tweet_in_zone_A.cache() #Probably not necessary; unless we want to do more with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we actually process any of this, let's figure out what we're going to do with it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = '/data/chime/geo/matthew_martin_palm_beach_inland'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_user_tweet_tuple_to_full_geojsonl(tuple_of_uid_tweets):\n",
    "    u_tweets = list(tuple_of_uid_tweets[1])\n",
    "    #We are not guaranteeing it's sorted by time here.\n",
    "    fileName = u_tweets[0]['actor']['preferredUsername'].lower() #Grab the username from the first tweet\n",
    "    write_full_tweets_to_geojsonl(outdir+'/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boom\n",
    "user_tweets_with_a_tweet_in_zone_A.foreach(write_user_tweet_tuple_to_full_geojsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Export Functions (Requires Local Arrays)\n",
    "(Also ALWAYS sorts by time; this could be expensive for large collections, but it's important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_full_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open(fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':t #Full GNIP Tweet in the properties\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_simplified_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            if 'location' in t:\n",
    "                loc = t['location']\n",
    "            else:\n",
    "                loc = None\n",
    "            if 'location' in t['actor']:\n",
    "                u_loc = t['actor']['location']\n",
    "            else:\n",
    "                u_loc = None\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'uid' :t['actor']['id'],\n",
    "                    'u_loc':u_loc,\n",
    "                    'u_reg':t['actor']['postedTime'],\n",
    "                    'u_sum':t['actor']['summary'],\n",
    "                    'tid' :t['id'],\n",
    "                    'loc' :loc,\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body'],\n",
    "                    'source':t['generator'],\n",
    "                    'verb':t['verb'],\n",
    "                    'meta':t['twitter_entities'],\n",
    "                    'u_utc':t['actor']['utcOffset']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_bare_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter for those tweets in ZoneA\n",
    "inZoneA = tweets_with_geo.filter(lambda t: zoneABroadcast.value.contains( shape(t['geo']) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Group by user (for inside of Zone A)\n",
    "inZoneA_gb_user = inZoneA.groupBy(lambda t: t['actor']['id']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_with_at_least_one_tweet_in_zoneA = [u[0] for u in inZoneA_gb_user]\n",
    "len(users_with_at_least_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# json.dump(users_with_at_least_one_tweet_in_zoneA, open('../working_data/users_with_at_least_one_tweet_in_zoneA.json','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the ZoneA tweets, but first, ensure it's sorted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets[0]['postedTime'])\n",
    "iso8601.parse_date(tweets[0]['postedTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (user, tweets) in inZoneA_gb_user:\n",
    "    tweets = [t for t in tweets]\n",
    "    userName = tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_full_tweets_to_geojsonl('../working_data/tweets_in_zone_a_by_user/'+userName, tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Tweets from these Users (Beyond just those in ZoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21951"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_one_tweet_in_zoneA = json.load(open('../working_data/users_with_at_least_one_tweet_in_zoneA.json'))\n",
    "len(users_with_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    if tuple_of_uid_tweets[0] in users_with_one_tweet_in_zoneA:\n",
    "        u_tweets = list(tuple_of_uid_tweets[1])\n",
    "        u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "        fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "        write_full_tweets_to_geojsonl('/data/chime/geo/users_with_a_tweet_in_zone_a/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the grouped by user tweets and if the uid matches a user with a tweet in zoneA, then write it out!\n",
    "tweets_gb_user.foreach(write_out_simplified_geo_contextual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.2)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
