{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, iso8601, fiona, pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Clean, Sort, Export from GNIP\n",
    "\n",
    "This notebook: \n",
    "\n",
    "1. Loads raw gnip data\n",
    "1. Filters for a geotag\n",
    "1. Identifies all tweets within an area of interest\n",
    "1. Finds Unique Users\n",
    "1. Writes full GNIP GEOJSONL files per user for users with at least 1 tweet in the area of interest\n",
    "\n",
    "## [Spark Status](http://epic-analytics.cs.colorado.edu:4040/jobs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the files\n",
    "raw_strings = sc.textFile('/data/chime/MovementDerivationGeoGNIP/VulnerableLocations/*/*')\n",
    "\n",
    "#Filter out the duds\n",
    "strings = raw_strings.filter(lambda x: x!=\"\")\n",
    "\n",
    "#JSONs\n",
    "jsons  = strings.map(json.loads)\n",
    "\n",
    "tweet_jsons = jsons.filter(lambda x: 'info' not in x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load all the Tweets!\n",
    "### 2 Crucial Steps\n",
    "1. A lot of tweets do not actually have lat/lon that will work for our purposes\n",
    "1. The GNIP `geo` field is backwards from convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_geo(t):\n",
    "    t['geo']['coordinates'].reverse()\n",
    "    return t\n",
    "\n",
    "tweets_with_geo = tweet_jsons.filter(lambda t: 'geo' in t.keys())\n",
    "\n",
    "geo_tweets = tweets_with_geo.map(fix_geo)\n",
    "# geo_tweets.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that this is working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'actor': {u'displayName': u'Your #2 (;',\n",
      "            u'favoritesCount': 33,\n",
      "            u'followersCount': 672,\n",
      "            u'friendsCount': 990,\n",
      "            u'id': u'id:twitter.com:331668063',\n",
      "            u'image': u'https://si0.twimg.com/profile_images/2643005436/5f541b91c7f5ec3adcacc471e8c911ea_normal.jpeg',\n",
      "            u'languages': [u'en'],\n",
      "            u'link': u'http://www.twitter.com/Dougieee_Nastyy',\n",
      "            u'links': [{u'href': None, u'rel': u'me'}],\n",
      "            u'listedCount': 0,\n",
      "            u'location': {u'displayName': u\"Your Girl's Bedroom ;)\",\n",
      "                          u'objectType': u'place'},\n",
      "            u'objectType': u'person',\n",
      "            u'postedTime': u'2011-07-08T14:52:11.000Z',\n",
      "            u'preferredUsername': u'Dougieee_Nastyy',\n",
      "            u'statusesCount': 7397,\n",
      "            u'summary': u\"- I'm your girls fantasy (; , #TeamGod #Philippians4: 13 #GrindHard #BallisLife . So just follow me and My Everything @B_MooreSeductiv , I'll lead you  . (; \",\n",
      "            u'twitterTimeZone': None,\n",
      "            u'utcOffset': None,\n",
      "            u'verified': False},\n",
      " u'body': u'- I do my own thing , you made me this way .',\n",
      " u'generator': {u'displayName': u'Twitter for Android',\n",
      "                u'link': u'http://twitter.com/download/android'},\n",
      " u'geo': {u'coordinates': [-74.5342206, 39.3954102], u'type': u'Point'},\n",
      " u'gnip': {u'language': {u'value': u'en'},\n",
      "           u'matching_rules': [{u'tag': u'[-74.53321912339669,39.36436374931048]',\n",
      "                                u'value': u'bounding_box:[-74.57813488760267 39.329638110038545 -74.48830335919072 39.39908938858241]'}]},\n",
      " u'id': u'tag:search.twitter.com,2005:261428248251092992',\n",
      " u'link': u'http://twitter.com/Dougieee_Nastyy/statuses/261428248251092992',\n",
      " u'location': {u'country_code': u'United States',\n",
      "               u'displayName': u'Pleasantville, NJ',\n",
      "               u'geo': {u'coordinates': [[[-74.550464, 39.356318],\n",
      "                                          [-74.485923, 39.356318],\n",
      "                                          [-74.485923, 39.418938],\n",
      "                                          [-74.550464, 39.418938]]],\n",
      "                        u'type': u'Polygon'},\n",
      "               u'link': u'http://api.twitter.com/1/geo/id/4439e5140bd8b701.json',\n",
      "               u'name': u'Pleasantville',\n",
      "               u'objectType': u'place',\n",
      "               u'twitter_country_code': u'US',\n",
      "               u'twitter_place_type': u'city'},\n",
      " u'object': {u'id': u'object:search.twitter.com,2005:261428248251092992',\n",
      "             u'link': u'http://twitter.com/Dougieee_Nastyy/statuses/261428248251092992',\n",
      "             u'objectType': u'note',\n",
      "             u'postedTime': u'2012-10-25T11:25:26.000Z',\n",
      "             u'summary': u'- I do my own thing , you made me this way .'},\n",
      " u'objectType': u'activity',\n",
      " u'postedTime': u'2012-10-25T11:25:26.000Z',\n",
      " u'provider': {u'displayName': u'Twitter',\n",
      "               u'link': u'http://www.twitter.com',\n",
      "               u'objectType': u'service'},\n",
      " u'retweetCount': 0,\n",
      " u'twitter_entities': {u'hashtags': [], u'urls': [], u'user_mentions': []},\n",
      " u'verb': u'post'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(geo_tweets.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Export subsets of the data as `.geojsonl` files\n",
    "This is not by user, this is all tweets in one file (i.e., BIG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "all_geo_tweets = tweets_with_geo.collect()\n",
    "write_full_tweets_to_geojsonl('all_geotagged_tweets_full', all_geo_tweets)\n",
    "write_bare_tweets_to_geojsonl('all_geotagged_tweets_bare', all_geo_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Group tweets by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[7] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_gb_user = geo_tweets.groupBy(lambda t: t['actor']['id'])\n",
    "tweets_gb_user.cache() #We should probably cache these? If we want to use them again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check on the status of this operation, should see a tuple of: `(user_id, iterable)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'id:twitter.com:883377476',\n",
      " <pyspark.resultiterable.ResultIterable object at 0x7f4ac4893410>)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(tweets_gb_user.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    u_tweets = list(tuple_of_uid_tweets[1])\n",
    "    u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "    fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_simplified_tweets_to_geojsonl('../working_data/simplified_geo_contextual_all_users/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Write the `geo-tweet-streams` for EVERY user "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tweets_gb_user.foreach( write_out_simplified_geo_contextual )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Geographic Filtering\n",
    "\n",
    "Load the shapefile for Evacuation Zone (or whatever your bounds should be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import mapping, shape\n",
    "import fiona\n",
    "c = fiona.open('../EvacuationZones/New_Jersey/coastline.shp','r')\n",
    "pol = c.next()\n",
    "geom = shape(pol['geometry'])\n",
    "geom.is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POINT (-73.99154663085938 40.361195540839)\n",
      "TRUE? True\n",
      "TRUE? True\n",
      "POINT (-73.99753114562988 40.73093368341445)\n",
      "FALSE? False\n"
     ]
    }
   ],
   "source": [
    "#Set as a broadcst variable for spark\n",
    "zoneBroadcast = sc.broadcast(geom)\n",
    "#Testing (For ZoneA):\n",
    "in_bounds = shape({'type': \"Point\", 'coordinates': [-73.99154663085938,40.361195540839]})\n",
    "print in_bounds\n",
    "print \"TRUE?\", zoneBroadcast.value.contains(in_bounds)\n",
    "print \"TRUE?\", in_bounds.within(zoneBroadcast.value)\n",
    "\n",
    "out_of_bounds = shape({\"type\": \"Point\",\"coordinates\": [-73.99753114562988,40.73093368341445]})\n",
    "print out_of_bounds\n",
    "print \"FALSE?\", zoneBroadcast.value.contains(out_of_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a function that takes an iterable and filters for users with a tweet in zoneA\n",
    "def has_tweet_in_bounds(iterable):\n",
    "    for t in iterable:\n",
    "        if zoneBroadcast.value.contains( shape(t['geo']) ):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the filter for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_tweets_with_a_tweet_in_zone_A = tweets_gb_user.filter(lambda _: has_tweet_in_bounds(_[1]))\n",
    "# user_tweets_with_a_tweet_in_zone_A.cache() #Probably not necessary; unless we want to do more with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we actually process any of this, let's figure out what we're going to do with it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outdir = '/data/chime/geo/sandy_new_jersey_coastline_users'\n",
    "\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_user_tweet_tuple_to_full_geojsonl(tuple_of_uid_tweets):\n",
    "    u_tweets = list(tuple_of_uid_tweets[1])\n",
    "    #We are not guaranteeing it's sorted by time here.\n",
    "    fileName = u_tweets[0]['actor']['preferredUsername'].lower() #Grab the username from the first tweet\n",
    "    write_full_tweets_to_geojsonl(outdir+'/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Boom\n",
    "user_tweets_with_a_tweet_in_zone_A.foreach(write_user_tweet_tuple_to_full_geojsonl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Export Functions (Requires Local Arrays)\n",
    "(Also ALWAYS sorts by time; this could be expensive for large collections, but it's important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_full_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open(fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':t #Full GNIP Tweet in the properties\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_simplified_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            if 'location' in t:\n",
    "                loc = t['location']\n",
    "            else:\n",
    "                loc = None\n",
    "            if 'location' in t['actor']:\n",
    "                u_loc = t['actor']['location']\n",
    "            else:\n",
    "                u_loc = None\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'uid' :t['actor']['id'],\n",
    "                    'u_loc':u_loc,\n",
    "                    'u_reg':t['actor']['postedTime'],\n",
    "                    'u_sum':t['actor']['summary'],\n",
    "                    'tid' :t['id'],\n",
    "                    'loc' :loc,\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body'],\n",
    "                    'source':t['generator'],\n",
    "                    'verb':t['verb'],\n",
    "                    'meta':t['twitter_entities'],\n",
    "                    'u_utc':t['actor']['utcOffset']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_bare_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter for those tweets in ZoneA\n",
    "inZoneA = tweets_with_geo.filter(lambda t: zoneABroadcast.value.contains( shape(t['geo']) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Group by user (for inside of Zone A)\n",
    "inZoneA_gb_user = inZoneA.groupBy(lambda t: t['actor']['id']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_with_at_least_one_tweet_in_zoneA = [u[0] for u in inZoneA_gb_user]\n",
    "len(users_with_at_least_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# json.dump(users_with_at_least_one_tweet_in_zoneA, open('../working_data/users_with_at_least_one_tweet_in_zoneA.json','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the ZoneA tweets, but first, ensure it's sorted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets[0]['postedTime'])\n",
    "iso8601.parse_date(tweets[0]['postedTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (user, tweets) in inZoneA_gb_user:\n",
    "    tweets = [t for t in tweets]\n",
    "    userName = tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_full_tweets_to_geojsonl('../working_data/tweets_in_zone_a_by_user/'+userName, tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Tweets from these Users (Beyond just those in ZoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21951"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_one_tweet_in_zoneA = json.load(open('../working_data/users_with_at_least_one_tweet_in_zoneA.json'))\n",
    "len(users_with_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    if tuple_of_uid_tweets[0] in users_with_one_tweet_in_zoneA:\n",
    "        u_tweets = list(tuple_of_uid_tweets[1])\n",
    "        u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "        fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "        write_full_tweets_to_geojsonl('/data/chime/geo/users_with_a_tweet_in_zone_a/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the grouped by user tweets and if the uid matches a user with a tweet in zoneA, then write it out!\n",
    "tweets_gb_user.foreach(write_out_simplified_geo_contextual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.2)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
