{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2, multiprocessing, psycopg2.extras, os, json, sys, time, scipy, datetime\n",
    "from multiprocessing import Pool, Manager \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import shape, mapping\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_directory  = \"/data/chime/geo/zone_a_full_contexual/stage1\"\n",
    "output_directory = \"/data/chime/geo/zone_a_full_contexual/stage2\"\n",
    "\n",
    "#SANDY\n",
    "_landfall_str = '201210300000' #Need to define the new dates for Hurricane Matthew in these zones?\n",
    "_start_str    = '201210290000' # (ie when was the evacuation?)\n",
    "_end_str      = '201210310000'\n",
    "_landfall = pd.Timestamp(_landfall_str)\n",
    "_start    = pd.Timestamp(_start_str)\n",
    "_end      = pd.Timestamp(_end_str)\n",
    "\n",
    "#MATTHEW\n",
    "# _landfall_str = '201610060000' #Using these dates for Matthew...\n",
    "# _start_str    = '201610040000' # (ie when was the evacuation?)\n",
    "# _end_str      = '201610080000'\n",
    "# _landfall = pd.Timestamp(_landfall_str)\n",
    "# _start    = pd.Timestamp(_start_str)\n",
    "# _end      = pd.Timestamp(_end_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load all the geo-clustered tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1189 users in /data/chime/geo/zone_a_full_contexual/stage1\n"
     ]
    }
   ],
   "source": [
    "users_in = sorted(os.listdir(input_directory))\n",
    "print(\"Found {0} users in {1}\".format(len(users_in), input_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loader_function(args):\n",
    "    uFile, path, q = args\n",
    "    u = json.load(open(path+\"/\"+uFile,'r'))\n",
    "    tweets = []\n",
    "    for t in u['features']:\n",
    "        if t['geometry']:\n",
    "            t['properties']['geometry'] = shape(t['geometry'])\n",
    "        t['properties']['date'] = pd.Timestamp(t['properties']['date'])\n",
    "        tweets.append(t['properties'])\n",
    "    q.put(1)\n",
    "    return gpd.GeoDataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 1189, 100%"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, input_directory, q) for i in users_in]\n",
    "result = p.map_async(loader_function, args)\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "users = result.get()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1350575 total tweets for all users\n"
     ]
    }
   ],
   "source": [
    "print(\"{0} total tweets for all users\".format(sum([len(x) for x in users])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11zette17',\n",
       " '12912',\n",
       " '1djanoskians465',\n",
       " '2ndbananakara',\n",
       " '33amelie',\n",
       " '3ltutuykt',\n",
       " '40ozbreakfast',\n",
       " '4ever_divine',\n",
       " '4thfloorwalkup',\n",
       " '6degreesofgrace']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_names_in = [x[:-8] for x in users_in]\n",
    "user_names_in[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Identifying Temporal Clusters\n",
    "Use a custom _worker_ function to find specific time clusters\n",
    "\n",
    "## 1. Enough Tweets?\n",
    "\n",
    "Ensure that we have the following for each user:\n",
    "1. Geo-Cluter Information (If no geo-clusters are available, remove)\n",
    "2. Enough Tweets (At least *A* Tweet during the storm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_cluster(t):\n",
    "    t = t.tz_convert(\"EST\")\n",
    "    '''Get the timecluster'''\n",
    "    hour = t.hour//4 + 1\n",
    "    if t.weekday()>4:\n",
    "        return 6+hour\n",
    "    else:\n",
    "        return hour\n",
    "    \n",
    "def worker_function(args):\n",
    "    userDF, q = args\n",
    "    \n",
    "    #If no tweets around the time of the storm, then fail.\n",
    "    if len(userDF.query(\"date > %s & date < %s\"%(_start_str, _end_str))) < 1:\n",
    "        q.put(1)\n",
    "        return None\n",
    "    \n",
    "    userDF['day_cluster'] = userDF.date.apply(lambda t: time_cluster(t))\n",
    "    q.put(0)\n",
    "    return userDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 1189, 100%"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, q) for i in users]\n",
    "result = p.map_async(worker_function, args)\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "\n",
    "values = result.get()\n",
    "x = [i for i in values  if i is not None]\n",
    "nones = [i for i in values  if i is None]\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed 1188 users\n",
      "1 Users failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Successfully processed {0} users\\n{1} Users failed\".format(len(x),len(nones)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_past_first_step = [x.user[0].lower() for x in values if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11zette17',\n",
       " '1djanoskians465',\n",
       " '2ndbananakara',\n",
       " '33amelie',\n",
       " '3ltutuykt',\n",
       " '40ozbreakfast',\n",
       " '4ever_divine',\n",
       " '4thfloorwalkup',\n",
       " '6degreesofgrace',\n",
       " '7aflatna']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_past_first_step[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'12912'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Failed:\n",
    "set(user_names_in) - set(users_past_first_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_users = sorted(x, key=lambda y: len(y), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Group the clusters and find which geo-clusters correspond with home hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rank_clusters(df):\n",
    "    \"\"\"\n",
    "    There is definitely room for the logic in _this_ function to improve, but for now it looks good :) \n",
    "    \"\"\"\n",
    "    gb_geo = df.query('date < '+_start_str).groupby('cluster')\n",
    "    if len(gb_geo) < 1:\n",
    "        return (None,None)\n",
    "    _agged = gb_geo['day_cluster'].agg({\"tweets\":pd.Series.count,\n",
    "                                        \"Number Unique Times\":pd.Series.nunique,\n",
    "                                        \"day_cluster_counts\": lambda t: Counter(t),\n",
    "                                        \"HomeTimes\": lambda t: any(t==1) or any(t==2) or any(t==6),\n",
    "                                      }).sort_values('Number Unique Times', ascending=False).query('cluster>0')\n",
    "    hc = None\n",
    "    \n",
    "    #If there is a cluster with hometimes, then return that (highest rated based on unique times)\n",
    "    if len(_agged.query('HomeTimes'))>0:\n",
    "        hc = _agged.query('HomeTimes').iloc[0].name\n",
    "        \n",
    "    return hc, _agged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1188 of 1188\n",
      "\n",
      "Clustered: 1188, Failed: 0"
     ]
    }
   ],
   "source": [
    "vals= []\n",
    "len_users = len(_users)\n",
    "user_collection = []\n",
    "\n",
    "user_meta_collection = []\n",
    "for idx, U in enumerate(_users):\n",
    "    \n",
    "    hc = rank_clusters(U)[0]\n",
    "    if hc is None:\n",
    "        hc_coords = None\n",
    "    else:\n",
    "        hc_coords = U.query(\"cluster=={0}\".format(hc))['cluster_center'].values[0]\n",
    "        \n",
    "    user_meta_collection.append({\n",
    "            'user':U['user'].values[0],\n",
    "            'uid' :U['uid'].values[0],\n",
    "            'tweets':len(U),\n",
    "            'home_cluster': hc,\n",
    "            'home_cluster_coords':hc_coords\n",
    "        })\n",
    "\n",
    "    U['home_cluster_id'] = pd.Series(hc)\n",
    "    \n",
    "    sys.stderr.write(\"\\r{0} of {1}\".format(idx+1, len_users))\n",
    "_user_meta = pd.DataFrame(user_meta_collection)\n",
    "sys.stderr.write(\"\\n\\nClustered: {0}, Failed: {1}\".format( len(_user_meta[~np.isnan(_user_meta.home_cluster)]),\n",
    "                                                           len(_user_meta[ np.isnan(_user_meta.home_cluster)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_with_homes = [u for u in _users if u.home_cluster_id.count()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify which users do not make it past?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_past_second_step = [x.user[0].lower() for x in users_with_homes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitched_users = set(user_names_in) - set(users_past_second_step)\n",
    "len(pitched_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Export the User Meta Dataframe first\n",
    "with open(output_directory+'/'+'temporal_clustered_user_meta.json','w') as metaOut:\n",
    "    metaOut.write(_user_meta.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_cluster</th>\n",
       "      <th>home_cluster_coords</th>\n",
       "      <th>tweets</th>\n",
       "      <th>uid</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"type\": \"Point\", \"coordinates\": [-73.69254581...</td>\n",
       "      <td>27551</td>\n",
       "      <td>75153082</td>\n",
       "      <td>Andrewthemark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"type\": \"Point\", \"coordinates\": [-73.74597391...</td>\n",
       "      <td>17918</td>\n",
       "      <td>450803155</td>\n",
       "      <td>Da_BBCofQU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"type\": \"Point\", \"coordinates\": [-74.02219865...</td>\n",
       "      <td>16244</td>\n",
       "      <td>479562736</td>\n",
       "      <td>GinsburgJobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"type\": \"Point\", \"coordinates\": [-74.02152626...</td>\n",
       "      <td>13670</td>\n",
       "      <td>299975120</td>\n",
       "      <td>LGoonerHoward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>{\"type\": \"Point\", \"coordinates\": [-74.03652815...</td>\n",
       "      <td>11665</td>\n",
       "      <td>73987740</td>\n",
       "      <td>ReelTalker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_cluster                                home_cluster_coords  tweets  \\\n",
       "0           1.0  {\"type\": \"Point\", \"coordinates\": [-73.69254581...   27551   \n",
       "1           1.0  {\"type\": \"Point\", \"coordinates\": [-73.74597391...   17918   \n",
       "2           1.0  {\"type\": \"Point\", \"coordinates\": [-74.02219865...   16244   \n",
       "3           1.0  {\"type\": \"Point\", \"coordinates\": [-74.02152626...   13670   \n",
       "4           3.0  {\"type\": \"Point\", \"coordinates\": [-74.03652815...   11665   \n",
       "\n",
       "         uid           user  \n",
       "0   75153082  Andrewthemark  \n",
       "1  450803155     Da_BBCofQU  \n",
       "2  479562736   GinsburgJobs  \n",
       "3  299975120  LGoonerHoward  \n",
       "4   73987740     ReelTalker  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_user_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Write these users to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_mapping(p):\n",
    "    if p==None or np.isnan(p).any():\n",
    "        return None\n",
    "    else:\n",
    "        return mapping(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def safe_json_export(args):\n",
    "    df, path, q = args\n",
    "    df = df.copy()\n",
    "    uName = df.head(1).user.values[0].lower()\n",
    "    df['date'] = df['date'].apply(lambda t: datetime.datetime.strftime(t,'%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    #Write the metadata:\n",
    "    with open('/data/www/chime/movement-derivation/user-metadata/'+uName+\".geojson\",'w') as userMeta:\n",
    "        userMeta.write(df.query(\"cluster=={0}\".format(df.iloc[0].home_cluster_id)).cluster_center.values[0])\n",
    "\n",
    "    clean = df.where((pd.notnull(df)), None)\n",
    "    geojson = {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "    for _, row in clean.iterrows():\n",
    "        geom = safe_mapping(row.geometry)\n",
    "        feature = {'type':'Feature',\n",
    "                   'geometry':geom,\n",
    "                   'properties':row.to_dict()\n",
    "                    }\n",
    "        del feature['properties']['geometry']\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    with open(path+\"/\"+uName+'.geojson','w') as oFile:\n",
    "        json.dump(geojson, oFile) \n",
    "\n",
    "    if q is not None:\n",
    "        q.put(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting 1188 users to /data/chime/geo/zone_a_full_contexual/stage2\n",
      "Processed: 1188, 100%"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, output_directory, q) for i in users_with_homes]\n",
    "result = p.map_async(safe_json_export, args)\n",
    "\n",
    "sys.stderr.write(\"Exporting {0} users to {1}\\n\".format(len(args),output_directory))\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "p.close()\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "# End of Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><hr>\n",
    "# Beginning of Visual Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
