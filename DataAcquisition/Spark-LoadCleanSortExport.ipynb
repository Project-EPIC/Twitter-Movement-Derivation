{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, iso8601, fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load the files\n",
    "raw_strings = sc.textFile('/data/chime/MovementDerivationGeoGNIP/VulnerableLocations/*/*')\n",
    "\n",
    "#Filter out the duds\n",
    "strings = raw_strings.filter(lambda x: x!=\"\")\n",
    "\n",
    "#JSONs\n",
    "jsons  = strings.map(json.loads)\n",
    "\n",
    "tweet_jsons = jsons.filter(lambda x: 'info' not in x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, for some reason, not all the tweets have a `geo` field. Moreover, the GNIP `geo` field is backwards from convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_with_geo = tweet_jsons.filter(lambda t: 'geo' in t.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fix_geo(t):\n",
    "    t['geo']['coordinates'].reverse()\n",
    "    return t\n",
    "geo_tweets = tweets_with_geo.map(fix_geo)\n",
    "geo_tweets.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'actor': {u'displayName': u'Your #2 (;',\n",
       "   u'favoritesCount': 33,\n",
       "   u'followersCount': 672,\n",
       "   u'friendsCount': 990,\n",
       "   u'id': u'id:twitter.com:331668063',\n",
       "   u'image': u'https://si0.twimg.com/profile_images/2643005436/5f541b91c7f5ec3adcacc471e8c911ea_normal.jpeg',\n",
       "   u'languages': [u'en'],\n",
       "   u'link': u'http://www.twitter.com/Dougieee_Nastyy',\n",
       "   u'links': [{u'href': None, u'rel': u'me'}],\n",
       "   u'listedCount': 0,\n",
       "   u'location': {u'displayName': u\"Your Girl's Bedroom ;)\",\n",
       "    u'objectType': u'place'},\n",
       "   u'objectType': u'person',\n",
       "   u'postedTime': u'2011-07-08T14:52:11.000Z',\n",
       "   u'preferredUsername': u'Dougieee_Nastyy',\n",
       "   u'statusesCount': 7397,\n",
       "   u'summary': u\"- I'm your girls fantasy (; , #TeamGod #Philippians4: 13 #GrindHard #BallisLife . So just follow me and My Everything @B_MooreSeductiv , I'll lead you  . (; \",\n",
       "   u'twitterTimeZone': None,\n",
       "   u'utcOffset': None,\n",
       "   u'verified': False},\n",
       "  u'body': u'- I do my own thing , you made me this way .',\n",
       "  u'generator': {u'displayName': u'Twitter for Android',\n",
       "   u'link': u'http://twitter.com/download/android'},\n",
       "  u'geo': {u'coordinates': [-74.5342206, 39.3954102], u'type': u'Point'},\n",
       "  u'gnip': {u'language': {u'value': u'en'},\n",
       "   u'matching_rules': [{u'tag': u'[-74.53321912339669,39.36436374931048]',\n",
       "     u'value': u'bounding_box:[-74.57813488760267 39.329638110038545 -74.48830335919072 39.39908938858241]'}]},\n",
       "  u'id': u'tag:search.twitter.com,2005:261428248251092992',\n",
       "  u'link': u'http://twitter.com/Dougieee_Nastyy/statuses/261428248251092992',\n",
       "  u'location': {u'country_code': u'United States',\n",
       "   u'displayName': u'Pleasantville, NJ',\n",
       "   u'geo': {u'coordinates': [[[-74.550464, 39.356318],\n",
       "      [-74.485923, 39.356318],\n",
       "      [-74.485923, 39.418938],\n",
       "      [-74.550464, 39.418938]]],\n",
       "    u'type': u'Polygon'},\n",
       "   u'link': u'http://api.twitter.com/1/geo/id/4439e5140bd8b701.json',\n",
       "   u'name': u'Pleasantville',\n",
       "   u'objectType': u'place',\n",
       "   u'twitter_country_code': u'US',\n",
       "   u'twitter_place_type': u'city'},\n",
       "  u'object': {u'id': u'object:search.twitter.com,2005:261428248251092992',\n",
       "   u'link': u'http://twitter.com/Dougieee_Nastyy/statuses/261428248251092992',\n",
       "   u'objectType': u'note',\n",
       "   u'postedTime': u'2012-10-25T11:25:26.000Z',\n",
       "   u'summary': u'- I do my own thing , you made me this way .'},\n",
       "  u'objectType': u'activity',\n",
       "  u'postedTime': u'2012-10-25T11:25:26.000Z',\n",
       "  u'provider': {u'displayName': u'Twitter',\n",
       "   u'link': u'http://www.twitter.com',\n",
       "   u'objectType': u'service'},\n",
       "  u'retweetCount': 0,\n",
       "  u'twitter_entities': {u'hashtags': [], u'urls': [], u'user_mentions': []},\n",
       "  u'verb': u'post'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_tweets.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export subsets of the data as `.geojsonl` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_geo_tweets = tweets_with_geo.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write_full_tweets_to_geojsonl('all_geotagged_tweets_full', all_geo_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write_bare_tweets_to_geojsonl('all_geotagged_tweets_bare', all_geo_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group By User now to avoid headaches later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[8] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_gb_user = geo_tweets.groupBy(lambda t: t['actor']['id'])\n",
    "tweets_gb_user.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'id:twitter.com:883377476',\n",
       "  <pyspark.resultiterable.ResultIterable at 0x7f2a6c105e90>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_gb_user.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    u_tweets = list(tuple_of_uid_tweets[1])\n",
    "    u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "    fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_simplified_tweets_to_geojsonl('../working_data/simplified_geo_contextual_all_users/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Things TODO here: Create a directory of all user files, called the 'geo-contextual'\n",
    "tweets_gb_user.foreach( write_out_simplified_geo_contextual )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping, shape\n",
    "c = fiona.open('../ZoneA_Geometry/ZoneA/OGRGeoJSON.shp','r')\n",
    "pol = c.next()\n",
    "geom = shape(pol['geometry']).buffer(0)\n",
    "geom.is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zoneABroadcast = sc.broadcast(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing:\n",
    "in_bounds = shape({'type': \"Point\", 'coordinates': [-73.94900, 40.73389]})\n",
    "print in_bounds\n",
    "print \"TRUE?\", zoneABroadcast.value.contains(in_bounds)\n",
    "print \"TRUE?\", in_bounds.within(zoneABroadcast.value)\n",
    "\n",
    "out_of_bounds = shape({\"type\": \"Point\",\"coordinates\": [-73.99753114562988,40.73093368341445]})\n",
    "print out_of_bounds\n",
    "print \"FALSE?\", zoneABroadcast.value.contains(out_of_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter for those tweets in ZoneA\n",
    "inZoneA = tweets_with_geo.filter(lambda t: zoneABroadcast.value.contains( shape(t['geo']) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Group by user (for inside of Zone A)\n",
    "inZoneA_gb_user = inZoneA.groupBy(lambda t: t['actor']['id']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_with_at_least_one_tweet_in_zoneA = [u[0] for u in inZoneA_gb_user]\n",
    "len(users_with_at_least_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# json.dump(users_with_at_least_one_tweet_in_zoneA, open('../working_data/users_with_at_least_one_tweet_in_zoneA.json','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the ZoneA tweets, but first, ensure it's sorted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tweets[0]['postedTime'])\n",
    "iso8601.parse_date(tweets[0]['postedTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (user, tweets) in inZoneA_gb_user:\n",
    "    tweets = [t for t in tweets]\n",
    "    userName = tweets[0]['actor']['preferredUsername'].lower()\n",
    "    write_full_tweets_to_geojsonl('../working_data/tweets_in_zone_a_by_user/'+userName, tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all Tweets from these Users (Beyond just those in ZoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21951"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_one_tweet_in_zoneA = json.load(open('../working_data/users_with_at_least_one_tweet_in_zoneA.json'))\n",
    "len(users_with_one_tweet_in_zoneA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_out_simplified_geo_contextual(tuple_of_uid_tweets):\n",
    "    if tuple_of_uid_tweets[0] in users_with_one_tweet_in_zoneA:\n",
    "        u_tweets = list(tuple_of_uid_tweets[1])\n",
    "        u_tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "        fileName = u_tweets[0]['actor']['preferredUsername'].lower()\n",
    "        write_full_tweets_to_geojsonl('../working_data/all_tweets_from_zoneA_users/'+fileName,u_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterate through the grouped by user tweets and if the uid matches a user with a tweet in zoneA, then write it out!\n",
    "tweets_gb_user.foreach(write_out_simplified_geo_contextual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Export Functions (Requires Local Arrays)\n",
    "(Also ALWAYS sorts by time; this could be expensive for large collections, but it's important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_full_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "#         tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':t #Full GNIP Tweet in the properties\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_simplified_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "#         tweets.sort(key=lambda t: iso8601.parse_date(t['postedTime']))\n",
    "        for t in tweets:\n",
    "            if 'location' in t:\n",
    "                loc = t['location']\n",
    "            else:\n",
    "                loc = None\n",
    "            if 'location' in t['actor']:\n",
    "                u_loc = t['actor']['location']\n",
    "            else:\n",
    "                u_loc = None\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'uid' :t['actor']['id'],\n",
    "                    'u_loc':u_loc,\n",
    "                    'u_reg':t['actor']['postedTime'],\n",
    "                    'u_sum':t['actor']['summary'],\n",
    "                    'tid' :t['id'],\n",
    "                    'loc' :loc,\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body'],\n",
    "                    'source':t['generator'],\n",
    "                    'verb':t['verb'],\n",
    "                    'meta':t['twitter_entities'],\n",
    "                    'u_utc':t['actor']['utcOffset']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_bare_tweets_to_geojsonl(fileName, tweets):\n",
    "    with open('../working_data/'+fileName+'.geojsonl','w') as outFile:\n",
    "        for t in tweets:\n",
    "            geojson = {\n",
    "                'type':'Feature',\n",
    "                'geometry':t['geo'],\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'time':t['postedTime'],\n",
    "                    'text':t['body']\n",
    "                }\n",
    "            }\n",
    "            outFile.write(json.dumps(geojson)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.2)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
