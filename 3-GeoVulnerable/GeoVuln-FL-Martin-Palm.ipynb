{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are users home locations in Vulnerable Locations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; from multiprocessing import Pool, Manager; import numpy as np; import geopandas as gpd\n",
    "import matplotlib.pyplot as plt; import seaborn as sns\n",
    "import matplotlib, os, json, sys, time, datetime\n",
    "from bson import json_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_directory  = \"/data/chime/geo2/PROCESSED/FL/martin_palm_beach_counties_Stage2/\"\n",
    "output_directory = \"/data/chime/geo2/PROCESSED/FL/martin_palm_beach_counties_Stage3/\"\n",
    "zoneGeometry     = \"../EvacuationZones/Florida/martin_palm_et_al.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the ZoneA Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Collection.__next__() is buggy and will be removed in Fiona 2.0. Switch to `next(iter(collection))`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fiona, shapely; from osgeo import ogr; from shapely.geometry import mapping, shape\n",
    "c = fiona.open(zoneGeometry,'r')\n",
    "pol = c.next(); zone = shape(pol['geometry']).buffer(0); zone.is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the user metadata DF (Phasing this out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_user_meta = pd.read_json(input_directory+'/temporal_clustered_user_meta.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_cluster</th>\n",
       "      <th>home_cluster_coords</th>\n",
       "      <th>tweets</th>\n",
       "      <th>uid</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>{\"coordinates\": [-80.20819619047614, 25.861914...</td>\n",
       "      <td>10784</td>\n",
       "      <td>249831776</td>\n",
       "      <td>TotalTrafficMIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.0</td>\n",
       "      <td>{\"coordinates\": [-78.01829999999997, 33.914999...</td>\n",
       "      <td>3523</td>\n",
       "      <td>4754740136</td>\n",
       "      <td>ebbtidebot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"coordinates\": [-80.0692510000025, 26.3507769...</td>\n",
       "      <td>3213</td>\n",
       "      <td>174303316</td>\n",
       "      <td>ClickWhisperer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_cluster                                home_cluster_coords  tweets  \\\n",
       "0          11.0  {\"coordinates\": [-80.20819619047614, 25.861914...   10784   \n",
       "1         134.0  {\"coordinates\": [-78.01829999999997, 33.914999...    3523   \n",
       "2           1.0  {\"coordinates\": [-80.0692510000025, 26.3507769...    3213   \n",
       "\n",
       "          uid             user  \n",
       "0   249831776  TotalTrafficMIA  \n",
       "1  4754740136       ebbtidebot  \n",
       "2   174303316   ClickWhisperer  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_user_meta = _user_meta.sort_index()\n",
    "_user_meta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import all of the individual user dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 363 users in /data/chime/geo2/PROCESSED/FL/martin_palm_beach_counties_Stage2/\n"
     ]
    }
   ],
   "source": [
    "users_in = sorted(os.listdir(input_directory))\n",
    "users_in = [x for x in users_in if x != \"temporal_clustered_user_meta.json\"]\n",
    "print(\"Found {0} users in {1}\".format(len(users_in), input_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loader_function(args):\n",
    "    uFile, path, q = args\n",
    "    u = json.load(open(path+\"/\"+uFile,'r'))\n",
    "    tweets = []\n",
    "    for t in u['features']:\n",
    "        if t['geometry']:\n",
    "            t['properties']['geometry'] = shape(t['geometry'])\n",
    "        t['properties']['date'] = pd.Timestamp(t['properties']['date'])\n",
    "        tweets.append(t['properties'])\n",
    "    q.put(1)\n",
    "    return gpd.GeoDataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 363, 100%%"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, input_directory, q) for i in users_in]\n",
    "result = p.map_async(loader_function, args)\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "users = result.get()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users.sort( key=lambda x: len(x), reverse=True ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`users` is an array of user dataframes. Now find which users have _home locations_ in Zone A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_center</th>\n",
       "      <th>coords</th>\n",
       "      <th>date</th>\n",
       "      <th>day_cluster</th>\n",
       "      <th>geo_delta</th>\n",
       "      <th>geometry</th>\n",
       "      <th>home_cluster_id</th>\n",
       "      <th>speed</th>\n",
       "      <th>text</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{\"coordinates\": [-76.31451879999999, 36.867423...</td>\n",
       "      <td>[-76.3145188, 36.8674231]</td>\n",
       "      <td>2016-09-23 09:44:35+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (-76.3145188 36.8674231)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can you recommend anyone for this #job in #Nor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>779255131376197632</td>\n",
       "      <td>2587789764</td>\n",
       "      <td>WorkWithSHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster                                     cluster_center  \\\n",
       "0        1  {\"coordinates\": [-76.31451879999999, 36.867423...   \n",
       "\n",
       "                      coords                      date  day_cluster  \\\n",
       "0  [-76.3145188, 36.8674231] 2016-09-23 09:44:35+00:00            2   \n",
       "\n",
       "   geo_delta                        geometry  home_cluster_id  speed  \\\n",
       "0        NaN  POINT (-76.3145188 36.8674231)              8.0    NaN   \n",
       "\n",
       "                                                text  time_delta  \\\n",
       "0  Can you recommend anyone for this #job in #Nor...         NaN   \n",
       "\n",
       "             tweet_id         uid         user  \n",
       "0  779255131376197632  2587789764  WorkWithSHC  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = users[10]\n",
    "print(len(x))\n",
    "x.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_home_cluster_center(userDF):\n",
    "    return shape(json.loads(userDF.query('cluster=='+str(userDF.home_cluster_id.values[0])).cluster_center.values[0]))\n",
    "\n",
    "get_home_cluster_center(users[0]).within(zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determine who's home cluster center is in ZONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insideZone(p):\n",
    "    if p==None:\n",
    "        return False\n",
    "    else:\n",
    "        return p.within(zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done...Identified 13 vulnerable users and 350 non-vulnerable"
     ]
    }
   ],
   "source": [
    "vuln = []\n",
    "non_vuln = []\n",
    "for idx, u in enumerate(users):\n",
    "    if (insideZone(get_home_cluster_center(u))):\n",
    "        vuln.append(u)\n",
    "    else:\n",
    "        non_vuln.append(u)\n",
    "    sys.stderr.write(\"\\r\"+str(idx+1))\n",
    "sys.stderr.write(\"\\rDone...\")\n",
    "sys.stderr.write(\"Identified {0} vulnerable users and {1} non-vulnerable\".format(len(vuln),len(non_vuln)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write out just the GeoVulnerable, just in case we need them for something later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_mapping(p):\n",
    "    if p==None or np.isnan(p).any():\n",
    "        return None\n",
    "    else:\n",
    "        return mapping(p)\n",
    "def safe_json_export(args):\n",
    "    df, path = args\n",
    "    df = df.copy()\n",
    "    uName = df.head(1).user.values[0].lower()\n",
    "    df['date'] = df['date'].apply(lambda t: datetime.datetime.strftime(t,'%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    clean = df.where((pd.notnull(df)), None)\n",
    "    geojson = {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "    for _, row in clean.iterrows():\n",
    "        geom = safe_mapping(row.geometry)\n",
    "        feature = {'type':'Feature',\n",
    "                   'geometry':geom,\n",
    "                   'properties':row.to_dict()\n",
    "                    }\n",
    "        del feature['properties']['geometry']\n",
    "        geojson['features'].append(feature)\n",
    "    \n",
    "    with open(path+\"/\"+uName+'.geojson','w') as oFile:\n",
    "        json.dump(geojson, oFile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13 processed"
     ]
    }
   ],
   "source": [
    "for idx, u in enumerate(vuln):\n",
    "    safe_json_export((u,output_directory))\n",
    "    sys.stderr.write(\"\\r{0} processed\".format(idx+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare for Analysis\n",
    "\n",
    "All of these users should already exist in a format prepared for visualizing, these users can be pasted into Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3idinfantryvet\n",
      "clickwhisperer\n",
      "drsherryroth\n",
      "engstrom_roger\n",
      "fuzzydogphotos\n",
      "itsme_raquel_\n",
      "karlykane\n",
      "msunitedam\n",
      "nica225\n",
      "pipemanradio\n",
      "shrimptank\n",
      "swimminglisa\n",
      "valeriesteblyuk\n"
     ]
    }
   ],
   "source": [
    "for uName in sorted([u.user[0].lower() for u in vuln]):\n",
    "    print(uName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vuln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3idinfantryvet\n",
      "clickwhisperer\n",
      "drsherryroth\n",
      "engstrom_roger\n",
      "fuzzydogphotos\n",
      "itsme_raquel_\n",
      "nica225\n",
      "pipemanradio\n",
      "shrimptank\n",
      "valeriesteblyuk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0\r",
      "1\r",
      "2\r",
      "3\r",
      "4\r",
      "5\r",
      "6\r",
      "7\r",
      "8\r",
      "9\r",
      "10\r",
      "11\r",
      "12\r",
      "10"
     ]
    }
   ],
   "source": [
    "def good_storm_tweets(userDF):\n",
    "    return len(userDF.query(\"date > 201610040000 & date < 201610080000\")) \n",
    "    \n",
    "good_data = []\n",
    "res = []\n",
    "for idx, u in enumerate(vuln):\n",
    "    if good_storm_tweets(u) > 2:\n",
    "        good_data.append(u)\n",
    "    \n",
    "    sys.stderr.write(\"\\r\"+str(idx))\n",
    "\n",
    "sys.stderr.write(\"\\r\"+str(len(good_data)))\n",
    "for uName in sorted([u.user[0].lower() for u in good_data]):\n",
    "    print(uName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create rules file from UID"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rules = []\n",
    "these_rules = []\n",
    "for idx,u in enumerate(vuln):\n",
    "\n",
    "    rule = \"from:\"+u.uid[0]\n",
    "    these_rules.append(rule)\n",
    "    \n",
    "    if idx%25==0 and idx>0:\n",
    "        rules.append(\" OR \".join(these_rules))\n",
    "        these_rules = []\n",
    "\n",
    "output = []\n",
    "for r in rules:\n",
    "    output.append({\"value\":r})\n",
    "\n",
    "with open('../../GNIP/Sandy/NJ_GeoVulnerable_Contextual/rules.json','w') as oFile:\n",
    "    json.dump(output, oFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
