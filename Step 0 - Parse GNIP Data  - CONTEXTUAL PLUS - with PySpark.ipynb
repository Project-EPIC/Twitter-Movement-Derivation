{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, iso8601, pprint, os, codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, Clean, Sort, Convert GeoLocated data collected form Twitter (GNIP)\n",
    "\n",
    "This notebook: \n",
    "\n",
    "1. Loads raw gnip data\n",
    "1. Writes full GNIP GEOJSONL files per user\n",
    "\n",
    "## [Spark Status](http://epic-analytics.cs.colorado.edu:4040/jobs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_directory  = \"/data/chime/Hurricanes_HIM/contextual-plus/maria-geo-pr/GNIP/\"\n",
    "output_directory = \"/data/chime/geo2/MARIA-PR-CONTEXTUALPLUS/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load all the Tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the files\n",
    "raw_strings = sc.textFile(input_directory)\n",
    "\n",
    "#Filter out the duds\n",
    "strings = raw_strings.filter(lambda x: x!=\"\")\n",
    "\n",
    "#JSONs\n",
    "jsons  = strings.map(json.loads)\n",
    "\n",
    "tweets = jsons.filter(lambda x: 'info' not in x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that this is working so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'actor': {u'displayName': u'PR Accounting',\n",
      "            u'favoritesCount': 0,\n",
      "            u'followersCount': 462,\n",
      "            u'friendsCount': 315,\n",
      "            u'id': u'id:twitter.com:856869560',\n",
      "            u'image': u'https://pbs.twimg.com/profile_images/720870033031700480/K70PJyXS_normal.jpg',\n",
      "            u'languages': [u'en'],\n",
      "            u'link': u'http://www.twitter.com/tmj_ptr_acct',\n",
      "            u'links': [{u'href': u'http://www.careerarc.com/job-seeker',\n",
      "                        u'rel': u'me'}],\n",
      "            u'listedCount': 16,\n",
      "            u'location': {u'displayName': u'Puerto Rico',\n",
      "                          u'objectType': u'place'},\n",
      "            u'objectType': u'person',\n",
      "            u'postedTime': u'2012-10-01T19:08:28.000Z',\n",
      "            u'preferredUsername': u'tmj_ptr_acct',\n",
      "            u'statusesCount': 21,\n",
      "            u'summary': u'Follow this account for geo-targeted Accounting job tweets in Puerto Rico. Need help? Tweet us at @CareerArc!',\n",
      "            u'twitterTimeZone': u'Arizona',\n",
      "            u'utcOffset': u'-25200',\n",
      "            u'verified': False},\n",
      " u'body': u'#Trabajo alerta: QA AUDITOR - Gurabo, PR | PR Gov | #Gurabo, Gurabo https://t.co/iZHc3cqcMK #Contabilidad #Contratar #CareerArc',\n",
      " u'favoritesCount': 0,\n",
      " u'generator': {u'displayName': u'TweetMyJOBS',\n",
      "                u'link': u'http://www.tweetmyjobs.com'},\n",
      " u'geo': {u'coordinates': [18.2543987, -65.9729421], u'type': u'Point'},\n",
      " u'gnip': {u'matching_rules': [{u'id': 5500621779974076957,\n",
      "                                u'id_str': u'5500621779974076957',\n",
      "                                u'tag': u'856869560:tmj_ptr_acct:PR Accounting'}],\n",
      "           u'urls': [{u'expanded_status': 200,\n",
      "                      u'expanded_url': u'http://www.careerarc.com/es_pr/job-listing/kelly-services-jobs-qa-auditor-gurabo-pr-23804975?campaign_id=10517&src=1&utm_campaign=TW01&utm_medium=TW&utm_source=JC',\n",
      "                      u'expanded_url_description': u\"QA AUDITOR - Gurabo, PR Purpose : The QA Auditor is accountable for ensuring the conformance of the packaging processes to the current Good Manufacturing Practices and the company's policies and in...\",\n",
      "                      u'expanded_url_title': u'QA AUDITOR - Gurabo, PR in Gurabo, Gurabo',\n",
      "                      u'url': u'https://t.co/iZHc3cqcMK'}]},\n",
      " u'id': u'tag:search.twitter.com,2005:912997774706098177',\n",
      " u'link': u'http://twitter.com/tmj_ptr_acct/statuses/912997774706098177',\n",
      " u'location': {u'country_code': u'United States',\n",
      "               u'displayName': u'Gurabo, USA',\n",
      "               u'geo': {u'coordinates': [[[-65.975575, 18.251536],\n",
      "                                          [-65.975575, 18.260342],\n",
      "                                          [-65.969514, 18.260342],\n",
      "                                          [-65.969514, 18.251536]]],\n",
      "                        u'type': u'Polygon'},\n",
      "               u'link': u'https://api.twitter.com/1.1/geo/id/452be19fa681b5f2.json',\n",
      "               u'name': u'Gurabo',\n",
      "               u'objectType': u'place',\n",
      "               u'twitter_country_code': u'US',\n",
      "               u'twitter_place_type': u'city'},\n",
      " u'object': {u'id': u'object:search.twitter.com,2005:912997774706098177',\n",
      "             u'link': u'http://twitter.com/tmj_ptr_acct/statuses/912997774706098177',\n",
      "             u'objectType': u'note',\n",
      "             u'postedTime': u'2017-09-27T11:10:06.000Z',\n",
      "             u'summary': u'#Trabajo alerta: QA AUDITOR - Gurabo, PR | PR Gov | #Gurabo, Gurabo https://t.co/iZHc3cqcMK #Contabilidad #Contratar #CareerArc'},\n",
      " u'objectType': u'activity',\n",
      " u'postedTime': u'2017-09-27T11:10:06.000Z',\n",
      " u'provider': {u'displayName': u'Twitter',\n",
      "               u'link': u'http://www.twitter.com',\n",
      "               u'objectType': u'service'},\n",
      " u'retweetCount': 0,\n",
      " u'twitter_entities': {u'hashtags': [{u'indices': [0, 8],\n",
      "                                      u'text': u'Trabajo'},\n",
      "                                     {u'indices': [52, 59],\n",
      "                                      u'text': u'Gurabo'},\n",
      "                                     {u'indices': [92, 105],\n",
      "                                      u'text': u'Contabilidad'},\n",
      "                                     {u'indices': [106, 116],\n",
      "                                      u'text': u'Contratar'},\n",
      "                                     {u'indices': [117, 127],\n",
      "                                      u'text': u'CareerArc'}],\n",
      "                       u'symbols': [],\n",
      "                       u'urls': [{u'display_url': u'bit.ly/2ydd1vE',\n",
      "                                  u'expanded_url': u'http://bit.ly/2ydd1vE',\n",
      "                                  u'indices': [68, 91],\n",
      "                                  u'url': u'https://t.co/iZHc3cqcMK'}],\n",
      "                       u'user_mentions': []},\n",
      " u'twitter_filter_level': u'low',\n",
      " u'twitter_lang': u'sl',\n",
      " u'verb': u'post'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(tweets.take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5:  Expand collection to all matching rules before grouping On User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_rdd = \n",
    "\n",
    "test = tweets.filter(lambda t: len(t['gnip']['matching_rules'])>1)\n",
    "\n",
    "#Going to have to ask Gerard more about this one...\n",
    "\n",
    "# Example: [{u'id': 163901075970690121,\n",
    "#      u'id_str': u'163901075970690121',\n",
    "#      u'tag': u'1365318420:MaybeImNicolee:Nasty Gal\\u26a1 \\U0001f49b'},\n",
    "#     {u'id': 2995764339274592720,\n",
    "#      u'id_str': u'2995764339274592720',\n",
    "#      u'tag': u'2840774861:skateromero21:Erick Romero \\U0001f4f7'}],\n",
    "\n",
    "type(test)\n",
    "#tweets_gb_user = tweet_jsons.groupBy(lambda t: t['gnip']['matching_rules'][0]['tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Group tweets by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[72] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_gb_user = tweets.groupBy(lambda t: t['actor']['id'])\n",
    "tweets_gb_user.cache() #We should probably cache these? If we want to use them again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check on the status of this operation, should see a tuple of: `(user_id, iterable)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'id:twitter.com:98402043',\n",
      " <pyspark.resultiterable.ResultIterable object at 0x7f3cf2663790>)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(tweets_gb_user.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeGeoJSON(uTuple):\n",
    "    u, iterable = uTuple\n",
    "    tweets = list(iterable)\n",
    "    handle = tweets[0]['actor']['preferredUsername']\n",
    "    tweets.sort(key=lambda t: t['postedTime'])\n",
    "    \n",
    "    #First, check for `geo`\n",
    "    features = []\n",
    "    geo_count = 0;\n",
    "    \n",
    "    for t in tweets:\n",
    "        try:\n",
    "            geo = t.get('geo',None)\n",
    "            if geo:\n",
    "                geo_count += 1;\n",
    "                geo = {'type':\"Point\",'coordinates':list(reversed(geo['coordinates']))}\n",
    "            feat = {\n",
    "                'type':'Feature',\n",
    "                'geometry': geo,\n",
    "                'properties':{\n",
    "                    'user':t['actor']['preferredUsername'],\n",
    "                    'text':t['body'],\n",
    "                    'date':t['postedTime'],\n",
    "                    'tweetID': t['id'].split(\":\")[2]\n",
    "                }\n",
    "            }\n",
    "            features.append(feat)\n",
    "        except:\n",
    "            raise\n",
    "    \n",
    "    #Minimum tweet count?\n",
    "    if geo_count > 5:\n",
    "        json.dump({'type':'FeatureCollection', 'features': features},\n",
    "                  codecs.open(output_directory + handle+\".geojson\",'w'))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write out the `geojsonl` files\n",
    "\n",
    "For now just writing the full GNIP files, but in the future, this can probably be streamlined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_gb_user.foreach( writeGeoJSON )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.5.2)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
