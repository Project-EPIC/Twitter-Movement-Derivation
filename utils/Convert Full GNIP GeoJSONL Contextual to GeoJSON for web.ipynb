{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn a directory into something that can be easily visualized on a map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np; from multiprocessing import Pool, Manager; import numpy as np;\n",
    "import fiona, shapely; from osgeo import ogr; from shapely.geometry import mapping, shape\n",
    "import matplotlib.pyplot as plt; import seaborn as sns\n",
    "import matplotlib, os, json, sys, time, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_directory  = \"/data/chime/geo/sandy_new_jersey_geovulnerable_contextual_stage2\"\n",
    "output_directory = \"/data/www/chime/movement-derivation/sandy_new_jersey_geo_vulnerable_contextual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 329 users in /data/chime/geo/sandy_new_jersey_geovulnerable_contextual_stage2\n"
     ]
    }
   ],
   "source": [
    "users_in = sorted(os.listdir(input_directory))\n",
    "users_in = [x for x in users_in if x != \"temporal_clustered_user_meta.json\"]\n",
    "print(\"Found {0} users in {1}\".format(len(users_in), input_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loader_function(args):\n",
    "    user_geojsonl_file, input_directory, q = args\n",
    "    tweets = []\n",
    "    for line in open(input_directory+\"/\"+user_geojsonl_file,'r'):\n",
    "        t = json.loads(line.strip())\n",
    "        tweet = {'geometry':None}\n",
    "        if t['geometry']:\n",
    "            tweet['geometry'] = t['geometry']\n",
    "        tweet['date'] = pd.Timestamp(t['properties']['postedTime'])\n",
    "        tweet['text'] = t['properties']['body']\n",
    "        tweet['user'] = t['properties']['actor']['preferredUsername']\n",
    "        if 'cluster' in t['properties']:\n",
    "            c = t['properties']['cluster']\n",
    "        else:\n",
    "            c = 0\n",
    "        tweet['c'] = c\n",
    "\n",
    "        if 'speed' in t['properties']:\n",
    "            s = t['properties']['speed']\n",
    "        else:\n",
    "            s = 0\n",
    "        tweet['s'] = s\n",
    "\n",
    "        \n",
    "        tweets.append(tweet)\n",
    "    if q is not None:\n",
    "        q.put(1)\n",
    "    \n",
    "    df = pd.DataFrame(tweets)\n",
    "    df = df.sort_values(by='date')\n",
    "    \n",
    "    first_date = df['date'][0]\n",
    "    last_date  = df['date'][len(df)-1]\n",
    "    df['time'] = df['date'].apply(lambda x: datetime.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    df['m']    = df['date'].apply(lambda x: int((x - first_date).total_seconds()/60))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 0, 0%"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'postedTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.4/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-22-3d6cf0125686>\", line 9, in loader_function\n    tweet['date'] = pd.Timestamp(t['properties']['postedTime'])\nKeyError: 'postedTime'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8eafae906460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\rProcessed: {0}, {1:.3g}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0musers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'postedTime'"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, input_directory, q) for i in users_in]\n",
    "result = p.map_async(loader_function, args)\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "users = result.get()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write `geojson` files for the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad0(num):\n",
    "    if num<10:\n",
    "        return \"0\"+str(num)\n",
    "    else:\n",
    "        return str(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_contextual_stream_geojson(args):\n",
    "    u, output_directory, q = args\n",
    "    file = u['user'][0].lower()\n",
    "    geojson = {'type':'FeatureCollection', 'features':[]}\n",
    "    for _, row in u.iterrows():\n",
    "        if pd.notnull(row.geometry):\n",
    "            geom = row.geometry\n",
    "        else:\n",
    "            geom = None\n",
    "        feature = {'type':'Feature',\n",
    "                   'geometry':geom,\n",
    "                   'properties':{'time':row['time'],\n",
    "                                 'm':row['m'],\n",
    "                                 'user':row['user'],\n",
    "                                 'text':row['text'],\n",
    "                                 'c':row['c']\n",
    "                                 's':row['s']\n",
    "                                }\n",
    "            }\n",
    "        geojson['features'].append(feature)\n",
    " \n",
    "    \n",
    "    with open(output_directory+\"/\"+file+\".geojson\",'w') as oFile:\n",
    "        json.dump(geojson,oFile)\n",
    "        \n",
    "    if q is not None:\n",
    "        q.put(1)\n",
    "    return 1\n",
    "#     start = \"{0}-{1}-{2}T{3}:{4}\".format(first_date.year,pad0(first_date.month),pad0(first_date.day),pad0(first_date.hour),pad0(first_date.minute))\n",
    "#     end   = last_date.date()\n",
    "#     print(file + \"\\t\" +\"http://www.localhost:4000/geojson-tweets?geojson=http://epic-analytics.cs.colorado.edu:9000/\"+output_directory.replace('/data/www/','')+\"/{0}.geojson&start={1}&end={2}&unit=minutes\".format(file, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed: 1197, 100%"
     ]
    }
   ],
   "source": [
    "#Parallel runtime\n",
    "p = Pool(30)\n",
    "m = Manager()\n",
    "q = m.Queue()\n",
    "\n",
    "args = [(i, output_directory, q) for i in users]\n",
    "result = p.map_async(write_contextual_stream_geojson, args)\n",
    "\n",
    "# monitor loop\n",
    "while True:\n",
    "    if result.ready():\n",
    "        break\n",
    "    else:\n",
    "        size = q.qsize()\n",
    "        sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(size, size/len(args)*100))\n",
    "        time.sleep(0.5)\n",
    "sys.stderr.write(\"\\rProcessed: {0}, {1:.3g}%\".format(q.qsize(), q.qsize()/len(args)*100))\n",
    "result.get()\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Deprecated\n",
    "Use the below function iff using `.geojsonl` files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def loader_function(args):\n",
    "    user_geojsonl_file, input_directory, q = args\n",
    "    tweets = []\n",
    "    for line in open(input_directory+\"/\"+user_geojsonl_file,'r'):\n",
    "        t = json.loads(line.strip())\n",
    "        tweet = {'geometry':None}\n",
    "        if 'geometry' in t:\n",
    "            tweet['geometry'] = t['geometry']\n",
    "        tweet['date'] = pd.Timestamp(t['properties']['postedTime'])\n",
    "        tweet['text'] = t['properties']['body']\n",
    "        tweet['user'] = t['properties']['actor']['preferredUsername']\n",
    "        if 'cluster' in t['properties']:\n",
    "            c = t['properties']['cluster']\n",
    "        else:\n",
    "            c = 0\n",
    "        tweet['c'] = c\n",
    "\n",
    "        if 'speed' in t['properties']:\n",
    "            s = t['properties']['speed']\n",
    "        else:\n",
    "            s = 0\n",
    "        tweet['s'] = s\n",
    "\n",
    "        \n",
    "        tweets.append(tweet)\n",
    "    if q is not None:\n",
    "        q.put(1)\n",
    "    \n",
    "    df = pd.DataFrame(tweets)\n",
    "    df = df.sort_values(by='date')\n",
    "    \n",
    "    first_date = df['date'][0]\n",
    "    last_date  = df['date'][len(df)-1]\n",
    "    df['time'] = df['date'].apply(lambda x: datetime.datetime.strftime(x, '%Y-%m-%dT%H:%M:%SZ'))\n",
    "    df['m']    = df['date'].apply(lambda x: int((x - first_date).total_seconds()/60))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
